{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variants, lineages, and mutations set creation\n",
    "Variants, lineages, and mutations are of interest but are not necessarily confined to any specific topicCategory. Classifying for these might help to search for VOCs and VOIs.\n",
    "\n",
    "User regex to find specific lineages, or mutations\n",
    "\n",
    "Regex cheatcode:\n",
    "* '\\b' indicates word boundary\n",
    "* '()' indicates a capture group\n",
    "* '?:' indicates a non-capture group\n",
    "* '\\d' indicates a digit\n",
    "* '{1,5}' indicates repeat in pattern between 1 and 5 times (so in mutation example, one to five digits)\n",
    "* \"r' \" indicates raw string notation\n",
    "* (?i)(?-i) indicates everything between is case insensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data/'\n",
    "RESULTSPATH = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load all litcovid into a dataframe, and clean up the text for searching\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def get_ids_from_json(jsonfile):\n",
    "    idlist = []\n",
    "    for eachhit in jsonfile[\"hits\"]:\n",
    "        if eachhit[\"_id\"] not in idlist:\n",
    "            idlist.append(eachhit[\"_id\"])\n",
    "    return(idlist)\n",
    "\n",
    "def batch_fetch_meta(idlist):\n",
    "    ## Break the list of ids into smaller chunks so the API doesn't fail the post request\n",
    "    runs = round((len(idlist))/100,0)\n",
    "    i=0 \n",
    "    separator = ','\n",
    "    ## Create dummy dataframe to store the meta data\n",
    "    textdf = pd.DataFrame(columns = ['_id','abstract','name','description','date'])\n",
    "    while i < runs+1:\n",
    "        if len(idlist)<100:\n",
    "            sample = idlist\n",
    "        elif i == 0:\n",
    "            sample = idlist[i:(i+1)*100]\n",
    "        elif i == runs:\n",
    "            sample = idlist[i*100:len(idlist)]\n",
    "        else:\n",
    "            sample = idlist[i*100:(i+1)*100]\n",
    "        sample_ids = separator.join(sample)\n",
    "        ## Get the text-based metadata (abstract, title) and save it\n",
    "        r = requests.post(\"https://api.outbreak.info/resources/query/\", params = {'q': sample_ids, 'scopes': '_id', 'fields': 'name,abstract,description,date'})\n",
    "        if r.status_code == 200:\n",
    "            rawresult = pd.read_json(r.text)\n",
    "            checkcols = rawresult.columns\n",
    "            if (('description' not in checkcols) and ('abstract' in checkcols)):\n",
    "                rawresult['description']=\" \"\n",
    "            elif (('description' in checkcols) and ('abstract' not in checkcols)):\n",
    "                rawresult['abstract']=\" \"\n",
    "            elif (('description' not in checkcols) and ('abstract' not in checkcols)):\n",
    "                rawresult['abstract']=\" \"\n",
    "                rawresult['description']=\" \"\n",
    "            cleanresult = rawresult[['_id','name','abstract','description','date']].loc[rawresult['_score']==1].fillna(\" \").copy()\n",
    "            cleanresult.drop_duplicates(subset='_id',keep=\"first\", inplace=True)\n",
    "            textdf = pd.concat((textdf,cleanresult))\n",
    "        i=i+1\n",
    "    return(textdf)\n",
    "\n",
    "\n",
    "def merge_texts(df):\n",
    "    df.fillna('',inplace=True)\n",
    "    df['text'] = df['name'].astype(str).str.cat(df['abstract'].astype(str).str.cat(df['description'],sep=' '),sep=' ')\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def clean_texts(df):\n",
    "    df.fillna('',inplace=True)\n",
    "    df['cleantext'] = df['text']\n",
    "    df['cleantext'] = df['cleantext'].str.replace(r'\\W', ' ')\n",
    "    df['cleantext'] = df['cleantext'].str.replace(r'\\s+[a-zA-Z]\\s+', ' ')\n",
    "    df['cleantext'] = df['cleantext'].str.replace(r'\\^[a-zA-Z]\\s+', ' ')\n",
    "    df['cleantext'] = df['cleantext'].str.lower()   \n",
    "    return(df)\n",
    "\n",
    "\n",
    "#### Get the size of the source (to make it easy to figure out when to stop scrolling)\n",
    "def fetch_src_size(source):\n",
    "    pubmeta = requests.get(\"https://api.outbreak.info/resources/query?q=((@type:Publication) AND (curatedBy.name:\"+source+\"))&size=0&aggs=@type\")\n",
    "    pubjson = json.loads(pubmeta.text)\n",
    "    pubcount = int(pubjson[\"facets\"][\"@type\"][\"total\"])\n",
    "    return(pubcount)\n",
    "\n",
    "\n",
    "#### Ping the API and get all the ids for a specific source and scroll through the source until number of ids matches meta\n",
    "def get_source_ids(source):\n",
    "    source_size = fetch_src_size(source)\n",
    "    r = requests.get(\"https://api.outbreak.info/resources/query?q=((@type:Publication) AND (curatedBy.name:\"+source+\"))&fields=_id&fetch_all=true\")\n",
    "    response = json.loads(r.text)\n",
    "    idlist = get_ids_from_json(response)\n",
    "    try:\n",
    "        scroll_id = response[\"_scroll_id\"]\n",
    "        while len(idlist) < source_size:\n",
    "            r2 = requests.get(\"https://api.outbreak.info/resources/query?q=((@type:Publication) AND (curatedBy.name:\"+source+\"))&fields=_id&fetch_all=true&scroll_id=\"+scroll_id)\n",
    "            response2 = json.loads(r2.text)\n",
    "            idlist2 = set(get_ids_from_json(response2))\n",
    "            tmpset = set(idlist)\n",
    "            idlist = tmpset.union(idlist2)\n",
    "            try:\n",
    "                scroll_id = response2[\"_scroll_id\"]\n",
    "            except:\n",
    "                print(\"no new scroll id\")\n",
    "        return(idlist)\n",
    "    except:\n",
    "        return(idlist)\n",
    "\n",
    "\n",
    "def get_pub_ids(sourceset):\n",
    "    pub_srcs = {\"preprint\":[\"bioRxiv\",\"medRxiv\"],\"litcovid\":[\"litcovid\"],\n",
    "                \"other\":[\"Figshare\",\"Zenodo\",\"MRC Centre for Global Infectious Disease Analysis\"],\n",
    "                \"all\":[\"Figshare\",\"Zenodo\",\"MRC Centre for Global Infectious Disease Analysis\",\n",
    "                       \"bioRxiv\",\"medRxiv\",\"litcovid\"]}\n",
    "    sourcelist = pub_srcs[sourceset]\n",
    "    allids = []\n",
    "    for eachsource in sourcelist:\n",
    "        sourceids = get_source_ids(eachsource)\n",
    "        allids = list(set(allids).union(set(sourceids)))\n",
    "    return(allids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched all ids:  0:04:23.295269\n",
      "fetched all metadata:  0:23:11.731127\n",
      "merged all text:  0:00:00.660896\n",
      "            _id                                           abstract  \\\n",
      "0  pmid33588991  Before the coronavirus 2019 (COVID-19) pandemi...   \n",
      "1  pmid33778893                                                      \n",
      "\n",
      "                                                name description  \\\n",
      "0  Antimicrobial resistance and COVID-19: Interse...               \n",
      "1  Screening and Diagnostic Mammography Utilizati...               \n",
      "\n",
      "                  date                                               text  \n",
      "0  2021-02-18 00:00:00  Antimicrobial resistance and COVID-19: Interse...  \n",
      "1  2021-03-29 00:00:00  Screening and Diagnostic Mammography Utilizati...  \n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.now()\n",
    "allids = get_pub_ids('all')\n",
    "print('fetched all ids: ',datetime.now()-starttime)\n",
    "starttime = datetime.now()\n",
    "metadf = batch_fetch_meta(allids)\n",
    "print('fetched all metadata: ',datetime.now()-starttime)\n",
    "starttime = datetime.now()\n",
    "textdf = merge_texts(metadf)\n",
    "print('merged all text: ',datetime.now()-starttime)\n",
    "print(textdf.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf.to_csv('data/textdf.txt',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf = read_csv('data/textdf.txt',delimiter='\\t',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "1. Find and extract mutations\n",
    "2. Check frequency of mutations in publications to see if trends can be identified\n",
    "3. Train algorithms to see if any new true positives can be identified\n",
    "3. Do the same for lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Mutation training set creation\n",
    "import re\n",
    "\n",
    "genes = \"(?:ORF1a|ORF1b|S|ORF3a|ORF3b|E|M|ORF6|ORF7a|ORF7b|ORF8|N|ORF9b|ORF10|ORF14|3'UTR|3UTR)\"\n",
    "#proteins = \"S|E|N|M|(NSP|Nsp(?:1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16))\"\n",
    "geneprots = r\"\\b(?:ORF1a|ORF1b|Spike|spike|ORF3a|ORF3b|Envelope|envelope|M protein|M\\(pro\\)|ORF6|ORF7a|ORF7b|ORF8|ORF9b|ORF10|ORF14|3'UTR|3UTR|(?:(?:NSP|nsp|Nsp|N)(?:1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16)))\\b\"\n",
    "mutations = \"((?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y)\\d{1,5}(?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y))\"\n",
    "#mutations = \"^(?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y)\\d{1,5}(?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y)$\"\n",
    "\n",
    "#deletions = genes+\":\"+\"(?:DEL|Del|del)\"+\"\\d{}\"\n",
    "#deletion_ex = \"ORF8∆381, ORF7a∆81 and spike∆15, ∆15, 60/70-deletion\"\n",
    "#deletion_variant = r\"\\b(∆\\d{1,5} variant)\\b\"\n",
    "\n",
    "token_dict = {\n",
    "    'mutants':r'\\b((?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y)\\d{2,5}(?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y))\\b',\n",
    "    #'genemute':r\"\\b((?:ORF1a|ORF1b|S|ORF3a|ORF3b|E|M|ORF6|ORF7a|ORF7b|ORF8|N|ORF9b|ORF10|ORF14|3'UTR|3UTR):(?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y)\\d{1,5}(?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y))\\b\",\n",
    "    'genemute':r\"\\b((?:ORF1a|ORF1b|S|Spike|spike|ORF3a|ORF3b|E|Envelope|envelope|M|M protein|M\\(pro\\)|ORF6|ORF7a|ORF7b|ORF8|ORF9b|ORF10|ORF14|3'UTR|3UTR|(?:(?:NSP|nsp|Nsp|N)(?:1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16)))(?:\\s|:)(?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y)\\d{1,5}(?:A|C|D|E|F|G|H|I|K|L|M|N|P|Q|R|S|T|V|W|Y))\\b\",\n",
    "    'deletions':r\"\\b((?:ORF1a|ORF1b|S|Spike|spike|ORF3a|ORF3b|E|Envelope|envelope|M|M protein|M\\(pro\\)|ORF6|ORF7a|ORF7b|ORF8|ORF9b|ORF10|ORF14|3'UTR|3UTR|(?:(?:NSP|nsp|Nsp|N)(?:1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16)))(?:∆|(?:DEL|Del|del|:DEL|:Del|:del))\\d{1,5})\\b\",\n",
    "    'nonspec_deletion':r\"\\b((?:ORF1a|ORF1b|S|Spike|spike|ORF3a|ORF3b|E|Envelope|envelope|M|M protein|M\\(pro\\)|ORF6|ORF7a|ORF7b|ORF8|N|ORF9b|ORF10|ORF14|3'UTR|3UTR|(?:NSP|Nsp|nsp)(?:1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16))\\s(?:(?:\\d{1,5})(?:\\/)(?:\\d{1,5})|(?:\\d{1,5}))(?:\\s|-)(?:deletion))\\b\"\n",
    "}\n",
    "\n",
    "testtext = \"This gene is full of ORF1a∆123 variants or other kinds of NSP deletion variants. There are also various mutations like S:E484K which is also known just as E484K which is a spike gene mutation. There are also deletions on the spike protein such as S:DEL15 or S∆15 though it could also be S:del15 so to speak or spike:del15 or Sdel15. Imagine if there was an ORF1a:A645T or E:C163G mutation. There are also nonspecific deletions like 60/70-deletion or 145/162-deletion or ∆15. There can also be mutations or deletions in the NSP genes or proteins such as Nsp2∆115 or NSP1:del115. Is it b.1.91 going to work or will any sort of lineageb.1.91 work nope and the spike 60/70-deletion or maybe the NSP2 459 deletion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerlist(x):\n",
    "    lowerlist = []\n",
    "    for y in x:\n",
    "        entry = y.lower()\n",
    "        lowerlist.append(entry)\n",
    "    cleanlist = list(set(lowerlist))\n",
    "    return(cleanlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\pandas\\core\\strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  _id                                               name  \\\n",
      "0   2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "1   2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "2   2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "3   2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "28       pmid33525415  Chloroquine and Hydroxychloroquine Interact Di...   \n",
      "29       pmid33525415  Chloroquine and Hydroxychloroquine Interact Di...   \n",
      "30  2021.04.02.438288  An emerging SARS-CoV-2 mutant evading cellular...   \n",
      "31  2021.04.02.438288  An emerging SARS-CoV-2 mutant evading cellular...   \n",
      "33       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "34       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "35       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "36       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "37       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "38       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "39       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "41       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "42       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "43       pmid33184173  Analysis of genomic distributions of SARS-CoV-...   \n",
      "44       pmid32711254  Linear B-cell epitopes in the spike and nucleo...   \n",
      "45       pmid33788923  Estimation of secondary household attack rates...   \n",
      "\n",
      "                                             abstract description  \\\n",
      "0   SARS-CoV-2 developed global-pandemic with mill...               \n",
      "1   SARS-CoV-2 developed global-pandemic with mill...               \n",
      "2   SARS-CoV-2 developed global-pandemic with mill...               \n",
      "3   SARS-CoV-2 developed global-pandemic with mill...               \n",
      "28  The severe acute respiratory syndrome coronavi...               \n",
      "29  The severe acute respiratory syndrome coronavi...               \n",
      "30  During the current SARS-CoV-2 pandemic that is...               \n",
      "31  During the current SARS-CoV-2 pandemic that is...               \n",
      "33  Severe acute respiratory syndrome coronavirus ...               \n",
      "34  Severe acute respiratory syndrome coronavirus ...               \n",
      "35  Severe acute respiratory syndrome coronavirus ...               \n",
      "36  Severe acute respiratory syndrome coronavirus ...               \n",
      "37  Severe acute respiratory syndrome coronavirus ...               \n",
      "38  Severe acute respiratory syndrome coronavirus ...               \n",
      "39  Severe acute respiratory syndrome coronavirus ...               \n",
      "41  Severe acute respiratory syndrome coronavirus ...               \n",
      "42  Severe acute respiratory syndrome coronavirus ...               \n",
      "43  Severe acute respiratory syndrome coronavirus ...               \n",
      "44  BACKGROUND: Given the unceasing worldwide surg...               \n",
      "45  BACKGROUND: Sequencing of the SARS-CoV-2 viral...               \n",
      "\n",
      "                                                 text       date mutations  \\\n",
      "0   Conserved in 186 countries the RBD fraction of... 2021-04-26     Y489S   \n",
      "1   Conserved in 186 countries the RBD fraction of... 2021-04-26     Y453S   \n",
      "2   Conserved in 186 countries the RBD fraction of... 2021-04-26     T500S   \n",
      "3   Conserved in 186 countries the RBD fraction of... 2021-04-26     T500Y   \n",
      "28  Chloroquine and Hydroxychloroquine Interact Di... 2021-01-18      K26R   \n",
      "29  Chloroquine and Hydroxychloroquine Interact Di... 2021-01-18     P426A   \n",
      "30  An emerging SARS-CoV-2 mutant evading cellular... 2021-04-05     L452R   \n",
      "31  An emerging SARS-CoV-2 mutant evading cellular... 2021-04-05     Y453F   \n",
      "33  Analysis of genomic distributions of SARS-CoV-... 2020-11-13     C241T   \n",
      "34  Analysis of genomic distributions of SARS-CoV-... 2020-11-13    C3037T   \n",
      "35  Analysis of genomic distributions of SARS-CoV-... 2020-11-13     F924F   \n",
      "36  Analysis of genomic distributions of SARS-CoV-... 2020-11-13   C14408T   \n",
      "37  Analysis of genomic distributions of SARS-CoV-... 2020-11-13    P4715L   \n",
      "38  Analysis of genomic distributions of SARS-CoV-... 2020-11-13   A23403G   \n",
      "39  Analysis of genomic distributions of SARS-CoV-... 2020-11-13     D614G   \n",
      "41  Analysis of genomic distributions of SARS-CoV-... 2020-11-13   G28881A   \n",
      "42  Analysis of genomic distributions of SARS-CoV-... 2020-11-13   G28882A   \n",
      "43  Analysis of genomic distributions of SARS-CoV-... 2020-11-13   G28883C   \n",
      "44  Linear B-cell epitopes in the spike and nucleo... 2020-06-25      R20H   \n",
      "45  Estimation of secondary household attack rates... 2021-03-31     L452R   \n",
      "\n",
      "           gene_mentions  \n",
      "0                [spike]  \n",
      "1                [spike]  \n",
      "2                [spike]  \n",
      "3                [spike]  \n",
      "28               [spike]  \n",
      "29               [spike]  \n",
      "30               [spike]  \n",
      "31               [spike]  \n",
      "33  [nsp3, nsp12, spike]  \n",
      "34  [nsp3, nsp12, spike]  \n",
      "35  [nsp3, nsp12, spike]  \n",
      "36  [nsp3, nsp12, spike]  \n",
      "37  [nsp3, nsp12, spike]  \n",
      "38  [nsp3, nsp12, spike]  \n",
      "39  [nsp3, nsp12, spike]  \n",
      "41  [nsp3, nsp12, spike]  \n",
      "42  [nsp3, nsp12, spike]  \n",
      "43  [nsp3, nsp12, spike]  \n",
      "44     [envelope, spike]  \n",
      "45               [spike]  \n"
     ]
    }
   ],
   "source": [
    "mutationslist = pd.DataFrame(columns=['_id','name','abstract','description','text','date','mutations'])\n",
    "for eachkey in token_dict.keys():\n",
    "    tmpdf = textdf.loc[textdf['text'].str.contains(token_dict[eachkey])].copy()\n",
    "    tmpdf['mutations'] = tmpdf['text'].str.findall(token_dict[eachkey])\n",
    "    tmpmutationslist = tmpdf.explode('mutations').copy()\n",
    "    mutationslist = pd.concat((mutationslist,tmpmutationslist),ignore_index=True)\n",
    "mutationslist['date'] = pd.to_datetime(mutationslist['date'])\n",
    "mutationslist.drop_duplicates(keep='first',inplace=True)\n",
    "mutationslist['gene_mentions'] = mutationslist['text'].str.findall(geneprots)\n",
    "mutationslist['gene_mentions'] = mutationslist['gene_mentions'].apply(lambda x: lowerlist(x))\n",
    "print(mutationslist.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutationsclean = mutationslist[['_id','name','date','mutations','gene_mentions']].copy()\n",
    "mutationsclean.to_csv(os.path.join(RESULTSPATH,'mutations.tsv'),sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "humefactors = mutationslist.loc[mutationslist['text'].str.contains(\"polymorphism\")].copy()\n",
    "humefactors.drop_duplicates(keep=\"first\",inplace=True)\n",
    "humefactors.drop(columns=['abstract','text','description'],inplace=True)\n",
    "humefactors.to_csv(os.path.join(RESULTSPATH,'polymorphisms.tsv'),sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143248\n",
      "                 _id                                               name  \\\n",
      "0  2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "1  2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "2  2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "3  2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "4  2021.04.25.441361  Conserved in 186 countries the RBD fraction of...   \n",
      "\n",
      "                                            abstract description  \\\n",
      "0  SARS-CoV-2 developed global-pandemic with mill...               \n",
      "1  SARS-CoV-2 developed global-pandemic with mill...               \n",
      "2  SARS-CoV-2 developed global-pandemic with mill...               \n",
      "3  SARS-CoV-2 developed global-pandemic with mill...               \n",
      "4  SARS-CoV-2 developed global-pandemic with mill...               \n",
      "\n",
      "                                                text       date mutations  \n",
      "0  Conserved in 186 countries the RBD fraction of... 2021-04-26     Y489S  \n",
      "1  Conserved in 186 countries the RBD fraction of... 2021-04-26     Y453S  \n",
      "2  Conserved in 186 countries the RBD fraction of... 2021-04-26     T500S  \n",
      "3  Conserved in 186 countries the RBD fraction of... 2021-04-26     T500Y  \n",
      "4  Conserved in 186 countries the RBD fraction of... 2021-04-26     Y489S  \n",
      "     mutations       date  counts\n",
      "3905     N501Y 2021-05-03      20\n",
      "1264     D614G 2021-05-03      15\n",
      "3811     N440K 2021-05-03       7\n",
      "1663     E484K 2021-05-03       5\n",
      "3410     L452R 2021-05-03       5\n",
      "5537      T36N 2021-05-03       4\n",
      "3101     K417N 2021-05-03       3\n",
      "3676      N31S 2021-05-03       3\n",
      "1668     E484Q 2021-05-03       2\n",
      "1624     E484D 2021-05-03       2\n",
      "4650      Q57H 2021-05-03       2\n",
      "2034      G15S 2021-05-03       1\n",
      "4437     P681H 2021-05-03       1\n",
      "3249      L18F 2021-05-03       1\n",
      "2752     H655Y 2021-05-03       1\n",
      "5597     T716I 2021-05-03       1\n",
      "126      A222V 2021-05-03       1\n",
      "3171      K90R 2021-05-03       1\n",
      "1275     D796Y 2021-05-03       1\n",
      "5775     V197M 2021-05-03       1\n"
     ]
    }
   ],
   "source": [
    "print(len(textdf))\n",
    "#mutdf = textdf.loc[(textdf['text'].str.contains(token_dict['mutants']))].copy()\n",
    "#mutdf['mutations'] = mutdf['text'].str.findall(token_dict['mutants'])\n",
    "\n",
    "#mutdf['date'] = pd.to_datetime(mutdf['date'])\n",
    "#mutationslist = mutdf.explode('mutations').copy()\n",
    "#mutationslist.drop(['abstract','name','description'],axis=1,inplace=True)\n",
    "#sortedmutations = mutationslist.sort_values(['mutations','date'],ascending=[True,True])\n",
    "#mutationfrequency = mutationslist.groupby('mutations').size().reset_index(name='counts')\n",
    "mutationfrequency = mutationslist.groupby('mutations').resample('W-Mon', on='date').size().reset_index(name='counts').sort_values(by='date')\n",
    "mutationfrequency.sort_values(['date','counts'],ascending=[False,False],inplace=True)\n",
    "print(mutationslist.head(n=5))\n",
    "print(mutationfrequency.head(n=20))\n",
    "#singlementions = mutationfrequency['mutations'].loc[mutationfrequency['counts']<2].unique().tolist()\n",
    "#mutations2check = mutationslist.loc[mutationslist['mutations'].isin(singlementions)]\n",
    "#mutations2check.to_csv('data/variants/mutations_to_check.tsv',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    _id                                           abstract  \\\n",
      "27  2020.12.23.20248598  In this study, we report the sequencing of 180...   \n",
      "28         pmid33917138  A new variant of SARS-CoV-2 B.1.351 lineage (f...   \n",
      "52         pmid33707329  Here, we report the coding-complete genome seq...   \n",
      "52  2021.04.27.21255987  BackgroundThe emergence of SARS-CoV-2 variants...   \n",
      "2     2021.03.15.435528  Understanding the ability of SARS-CoV-2 vaccin...   \n",
      "..                  ...                                                ...   \n",
      "75         pmid33853970  Cases of SARS-CoV-2 infection in Manaus, Brazi...   \n",
      "59    2021.04.09.439181  The novel {beta}-coronavirus has caused sad lo...   \n",
      "39    2021.03.06.434059  A SARS-CoV-2 lineage designated as P.3 with mu...   \n",
      "88    2021.04.21.440801  Rapid whole genome sequencing of SARS-CoV-2 ha...   \n",
      "24    2021.03.24.436620  DNA sequence analysis recently identified the ...   \n",
      "\n",
      "                                                 name description  \\\n",
      "27  Genomic characterization of a novel SARS-CoV-2...               \n",
      "28  The Impact on Infectivity and Neutralization E...               \n",
      "52  Coding-Complete Genome Sequences and Mutation ...               \n",
      "52  Rapid and simultaneous identification of three...               \n",
      "2   Elicitation of broadly protective sarbecovirus...               \n",
      "..                                                ...         ...   \n",
      "75  Genomics and epidemiology of the P.1 SARS-CoV-...               \n",
      "59  Theoretical causes of the Brazilian P.1 and P....               \n",
      "39  Structural Analysis of Spike Protein Mutations...               \n",
      "88  Comparative Analysis of Emerging B.1.1.7+E484K...               \n",
      "24  B.1.526 SARS-CoV-2 variants identified in New ...               \n",
      "\n",
      "                   date                                               text  \n",
      "27  2020-12-26 00:00:00  Genomic characterization of a novel SARS-CoV-2...  \n",
      "28  2021-04-04 00:00:00  The Impact on Infectivity and Neutralization E...  \n",
      "52  2021-03-12 00:00:00  Coding-Complete Genome Sequences and Mutation ...  \n",
      "52  2021-04-27 00:00:00  Rapid and simultaneous identification of three...  \n",
      "2   2021-03-16 00:00:00  Elicitation of broadly protective sarbecovirus...  \n",
      "..                  ...                                                ...  \n",
      "75  2021-04-21 00:00:00  Genomics and epidemiology of the P.1 SARS-CoV-...  \n",
      "59  2021-04-10 00:00:00  Theoretical causes of the Brazilian P.1 and P....  \n",
      "39  2021-03-08 00:00:00  Structural Analysis of Spike Protein Mutations...  \n",
      "88  2021-04-21 00:00:00  Comparative Analysis of Emerging B.1.1.7+E484K...  \n",
      "24  2021-03-24 00:00:00  B.1.526 SARS-CoV-2 variants identified in New ...  \n",
      "\n",
      "[135 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#genemutdf = textdf.loc[textdf['text'].str.contains(token_dict['genemute'],case=False)].copy()\n",
    "#genemutdf = textdf.loc[textdf['text'].str.extract(token_dict['genemute'])].copy()\n",
    "genemutdf = textdf.loc[textdf['text'].str.contains('E484K')].copy()\n",
    "print(genemutdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Variant training set creation\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Variant of Concern 202012/01\", \"VOC-202012/01\", \"20B/501Y.V1\", \"20I/501Y.V1\", the 501Y.V2 variant\n",
    "Variant Under Investigation 202012/01 (VUI 202012/01 for short)\n",
    "\"the {location} variant\"\n",
    "\"variant in {location}\"\n",
    "\"\"\"\n",
    "\n",
    "the_variant = r\"((?i)the (?:\\w*|\\w*.\\w*) variant(?-i))\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              taxon lineage\n",
      "0           Guangzhou/GZMU0016/2020       A\n",
      "1       Beijing/Wuhan_IME-BJ07/2020       A\n",
      "2                Nanchang/JX90/2020       A\n",
      "3              USA/CA-CZB-1240/2020       A\n",
      "4               Nanchang/JX177/2020       A\n",
      "...                             ...     ...\n",
      "456347        Brazil/MG-LBI263/2021     P.1\n",
      "456348        Brazil/SP-819690/2021     P.1\n",
      "456349        Brazil/SP-827441/2021     P.1\n",
      "456350        Brazil/SP-827466/2021     P.1\n",
      "456351        Brazil/SP-827777/2021     P.1\n",
      "\n",
      "[456352 rows x 2 columns] 1286\n",
      "Empty DataFrame\n",
      "Columns: [taxon, lineage]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#### Lineage training set creation\n",
    "## More lineage names: \"https://www.the-scientist.com/news-opinion/a-guide-to-emerging-sars-cov-2-variants-68387\"\n",
    "\n",
    "## fetch lineages from :\"https://cov-lineages.org/lineages.html\"\n",
    "lineagetable = read_csv(\"https://raw.githubusercontent.com/cov-lineages/pango-designation/master/lineages.csv\",error_bad_lines=False,header=0)\n",
    "lineages = lineagetable['lineage'].loc[lineagetable['lineage'].str.len()>2].unique().tolist()\n",
    "print(lineagetable,len(lineages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generic search terms for filtering\n",
    "filter_terms = [\"variant\",\"voi\",\"voc\",\"mutant\",\"mutation\",\"lineage\",\"strain\",\"species\",\"clade\",\"branch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch lineages from Wikidata\n",
    "querylist = [\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "      ?item ?itemLabel ?itemAltLabel\n",
    "    WHERE \n",
    "    {\n",
    "      ?item wdt:P31 wd:Q104450895.        \n",
    "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "    }\"\"\", \n",
    "    \"\"\"\n",
    "    SELECT \n",
    "      ?item ?itemLabel ?itemAltLabel\n",
    "    WHERE \n",
    "    {\n",
    "      ?item wdt:P279 wd:Q82069695.\n",
    "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "    }\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "      ?item ?itemLabel ?itemAltLabel\n",
    "    WHERE \n",
    "    {\n",
    "      ?item wdt:P31 wd:Q105758262.\n",
    "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "    }\n",
    "    \"\"\"    \n",
    "]\n",
    "\n",
    "def variant_names(querylist): \n",
    "    from collections import OrderedDict\n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    variants = []\n",
    "    for query in querylist:\n",
    "        r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "        data = r.json()\n",
    "        for item in data['results']['bindings']:\n",
    "            try:\n",
    "                variants.append(OrderedDict({\n",
    "                'name': item['itemLabel']['value'],\n",
    "                'alias': item['itemLabel']['value']}))\n",
    "                tmp= item['itemAltLabel']['value'].split(',')\n",
    "                for altname in tmp:\n",
    "                    if len(altname.strip())>3:\n",
    "                        variants.append(OrderedDict({\n",
    "                        'name': item['itemLabel']['value'],\n",
    "                        'alias': altname\n",
    "                        }))\n",
    "            except:\n",
    "                variants.append(OrderedDict({\n",
    "                'name': item['itemLabel']['value'].strip(),\n",
    "                'alias': item['itemLabel']['value'].strip()\n",
    "                }))\n",
    "    wikivariants = pd.DataFrame(variants)\n",
    "    wikivariants.drop_duplicates(keep='first',inplace=True)\n",
    "    return(wikivariants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikivariants = variant_names(querylist)\n",
    "wikidict = {}\n",
    "i=0\n",
    "while i < len(wikivariants):\n",
    "    wikidict[wikivariants.iloc[i]['alias'].lower().strip()] = wikivariants.iloc[i]['name'].lower().strip()\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineage search, no additional regex formatting\n",
    "The issue with this method is that the (.) are not handled properly so things like N95 end up being included and an additional filtering is needed which may end up cutting out relevant entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5240\n",
      "1922\n",
      "900\n",
      "                    _id                                           abstract  \\\n",
      "85         pmid33580111  SARS-CoV-2 has spread rapidly around the world...   \n",
      "85         pmid33580111  SARS-CoV-2 has spread rapidly around the world...   \n",
      "29  2020.12.23.20248598  In this study, we report the sequencing of 180...   \n",
      "23    2021.04.23.441186  Severe acute respiratory syndrome coronavirus ...   \n",
      "30         pmid33917138  A new variant of SARS-CoV-2 B.1.351 lineage (f...   \n",
      "68    2021.02.18.431484  Several SARS-CoV-2 vaccines have received EUAs...   \n",
      "68    2021.02.18.431484  Several SARS-CoV-2 vaccines have received EUAs...   \n",
      "52         pmid33618008  OBJECTIVES: To evaluate the genomic diversity ...   \n",
      "52         pmid33618008  OBJECTIVES: To evaluate the genomic diversity ...   \n",
      "52         pmid33618008  OBJECTIVES: To evaluate the genomic diversity ...   \n",
      "\n",
      "                                                 name description  \\\n",
      "85  SARS-CoV-2 genomic surveillance in Rondônia, B...               \n",
      "85  SARS-CoV-2 genomic surveillance in Rondônia, B...               \n",
      "29  Genomic characterization of a novel SARS-CoV-2...               \n",
      "23  Binding mechanism of neutralizing Nanobodies t...               \n",
      "30  The Impact on Infectivity and Neutralization E...               \n",
      "68  A Combination Adjuvant for the Induction of Po...               \n",
      "68  A Combination Adjuvant for the Induction of Po...               \n",
      "52  Characterizing SARS-CoV-2 genome diversity cir...               \n",
      "52  Characterizing SARS-CoV-2 genome diversity cir...               \n",
      "52  Characterizing SARS-CoV-2 genome diversity cir...               \n",
      "\n",
      "                   date                                               text  \\\n",
      "85  2021-02-17 00:00:00  SARS-CoV-2 genomic surveillance in Rondônia, B...   \n",
      "85  2021-02-17 00:00:00  SARS-CoV-2 genomic surveillance in Rondônia, B...   \n",
      "29  2020-12-26 00:00:00  Genomic characterization of a novel SARS-CoV-2...   \n",
      "23  2021-04-26 00:00:00  Binding mechanism of neutralizing Nanobodies t...   \n",
      "30  2021-04-04 00:00:00  The Impact on Infectivity and Neutralization E...   \n",
      "68  2021-02-18 00:00:00  A Combination Adjuvant for the Induction of Po...   \n",
      "68  2021-02-18 00:00:00  A Combination Adjuvant for the Induction of Po...   \n",
      "52  2021-02-15 00:00:00  Characterizing SARS-CoV-2 genome diversity cir...   \n",
      "52  2021-02-15 00:00:00  Characterizing SARS-CoV-2 genome diversity cir...   \n",
      "52  2021-02-15 00:00:00  Characterizing SARS-CoV-2 genome diversity cir...   \n",
      "\n",
      "           lineages  \n",
      "85              B.1  \n",
      "85            B.1.1  \n",
      "29         B.1.1.28  \n",
      "23  Lineage B.1.351  \n",
      "30  Lineage B.1.351  \n",
      "68  Lineage B.1.351  \n",
      "68              P.1  \n",
      "52  Lineage B.1.1.7  \n",
      "52  Lineage B.1.351  \n",
      "52              P.1  \n"
     ]
    }
   ],
   "source": [
    "masterlist = list(set(lineages).union(set(wikivariants['alias'].tolist())))\n",
    "searchterm = ' | '.join(masterlist)\n",
    "filterterms = '|'.join(filter_terms)\n",
    "tmpdf = textdf.loc[textdf['text'].str.contains(searchterm)].copy()\n",
    "tmpdf['lineages'] = tmpdf['text'].str.findall(searchterm)\n",
    "rawlineageslist = tmpdf.explode('lineages').copy()\n",
    "cleanlineageslist = rawlineageslist.loc[rawlineageslist['text'].str.contains(filterterms)].copy()\n",
    "cleanlineageslist['lineages'] = [x.strip() for x in cleanlineageslist['lineages']]\n",
    "\n",
    "print(len(rawlineageslist))\n",
    "print(len(cleanlineageslist))\n",
    "    \n",
    "cleanlineageslist['lineages'].replace(wikidict,inplace=True)\n",
    "cleanlineageslist.drop_duplicates(keep='first',inplace=True)\n",
    "print(len(cleanlineageslist))\n",
    "print(cleanlineageslist.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lineages  publication counts\n",
      "98   Lineage B.1.1.7                 252\n",
      "100  Lineage B.1.351                 134\n",
      "122              P.1                  79\n",
      "115              N95                  59\n",
      "23               B.1                  26\n",
      "..               ...                 ...\n",
      "55         B.1.36.27                   1\n",
      "54         B.1.36.10                   1\n",
      "52         B.1.351)3                   1\n",
      "49         B.1.243.1                   1\n",
      "137              ZO1                   1\n",
      "\n",
      "[138 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "lineagecounts = cleanlineageslist.groupby('lineages').size().reset_index(name='publication counts')\n",
    "lineagecounts.sort_values('publication counts',ascending=False,inplace=True)\n",
    "print(lineagecounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional regex attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterlist = list(set(lineages).union(set(wikivariants['alias'].tolist())))\n",
    "#print(len(masterlist))\n",
    "searchterm = ' | '.join(masterlist)\n",
    "#re_str1 = r'\\b(?i)('\n",
    "#re_str2 = r')(?-i)'\n",
    "#rawstring = r\"{}\".format(searchterm)\n",
    "#searchregex = re.compile(re_str1 + rawstring + re_str2)\n",
    "filterterms = '|'.join(filter_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterlist = list(set(lineages).union(set(wikivariants['alias'].tolist())))\n",
    "regexlist = []\n",
    "for eachitem in masterlist:\n",
    "    #rawstring = r\"{}\".format(eachitem.strip().replace('.','\\.'))\n",
    "    searchstring = rf\"{re.escape(eachitem)}\"\n",
    "    #searchregex = re.compile(searchstring)\n",
    "    #print(searchregex)\n",
    "    regexlist.append(searchstring)\n",
    "    #checkdf = textdf.loc[textdf['text'].str.contains(searchregex)].copy()\n",
    "    #if len(checkdf)>0:\n",
    "    #    checkdf['lineages'] = checkdf['text'].str.findall(searchregex)\n",
    "    #    print(checkdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964\n"
     ]
    }
   ],
   "source": [
    "#searchterms = '|'.join(regexlist)\n",
    "searchregex = re.compile('|'.join(regexlist), re.IGNORECASE)\n",
    "lineagedf = textdf.loc[textdf['text'].str.contains(searchregex)].copy()\n",
    "lineagedf['lineages'] = lineagedf['text'].str.findall(searchregex)\n",
    "print(len(lineagedf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2802\n",
      "2802\n",
      "1667\n",
      "                    _id                                               name  \\\n",
      "68    2021.04.02.438288  An emerging SARS-CoV-2 mutant evading cellular...   \n",
      "68    2021.04.02.438288  An emerging SARS-CoV-2 mutant evading cellular...   \n",
      "73         pmid33788923  Estimation of secondary household attack rates...   \n",
      "73         pmid33788923  Estimation of secondary household attack rates...   \n",
      "85         pmid33580111  SARS-CoV-2 genomic surveillance in Rondônia, B...   \n",
      "85         pmid33580111  SARS-CoV-2 genomic surveillance in Rondônia, B...   \n",
      "63         pmid33147321  An unconventional view of COVID-19 T cell immu...   \n",
      "97         pmid32576424  Stress, Anxiety, and Depression in People Aged...   \n",
      "29  2020.12.23.20248598  Genomic characterization of a novel SARS-CoV-2...   \n",
      "99         pmid33881861  Fast Prediction of Binding Affinities of the S...   \n",
      "\n",
      "                   date         lineages  \n",
      "68  2021-04-05 00:00:00          b.1.427  \n",
      "68  2021-04-05 00:00:00            b.1.2  \n",
      "73  2021-03-31 00:00:00          b.1.427  \n",
      "73  2021-03-31 00:00:00          b.1.429  \n",
      "85  2021-02-17 00:00:00              b.1  \n",
      "85  2021-02-17 00:00:00            b.1.1  \n",
      "63  2020-11-09 00:00:00              m.2  \n",
      "97  2020-05-16 00:00:00              v.2  \n",
      "29  2020-12-26 00:00:00            b.1.1  \n",
      "99  2021-04-21 00:00:00  lineage b.1.1.7  \n"
     ]
    }
   ],
   "source": [
    "rawlineageslist = lineagedf.explode('lineages').copy()\n",
    "#cleanlineageslist = rawlineageslist.loc[rawlineageslist['text'].str.contains(filterterms)].copy()\n",
    "cleanlineageslist = rawlineageslist[['_id','name','date','lineages']].copy()\n",
    "cleanlineageslist['lineages'] = [x.strip().lower() for x in cleanlineageslist['lineages']]\n",
    "\n",
    "print(len(rawlineageslist))\n",
    "print(len(cleanlineageslist))\n",
    "    \n",
    "cleanlineageslist['lineages'].replace(wikidict,inplace=True)\n",
    "cleanlineageslist.drop_duplicates(keep='first',inplace=True)\n",
    "print(len(cleanlineageslist))\n",
    "print(cleanlineageslist.head(n=10))\n",
    "cleanlineageslist.to_csv('results/lineages.tsv',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lineages  counts\n",
      "35           b.1.1.7     315\n",
      "47           b.1.351     138\n",
      "122              p.1     104\n",
      "128              s.1      88\n",
      "21             b.1.1      68\n",
      "20               b.1      59\n",
      "103  lineage b.1.1.7      47\n",
      "49   b.1.351 variant      45\n",
      "36   b.1.1.7 lineage      43\n",
      "132              v.1      39\n",
      "            lineages  counts\n",
      "24         b.1.1.117       1\n",
      "68              b.27       1\n",
      "105  lineage b.1.429       1\n",
      "67              b.26       1\n",
      "65              b.15       1\n",
      "64              b.13       1\n",
      "61   b.1.617 variant       1\n",
      "111              m.3       1\n",
      "18              an.1       1\n",
      "27         b.1.1.251       1\n"
     ]
    }
   ],
   "source": [
    "frequency = cleanlineageslist.groupby('lineages').size().reset_index(name='counts')\n",
    "frequency.sort_values('counts',ascending=False,inplace=True)\n",
    "print(frequency.head(n=10))\n",
    "print(frequency.tail(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
